# EXP-1-PROMPT-ENGINEERING-

## Aim: 
Comprehensive Report on the Fundamentals of Generative AI and Large Language Models (LLMs)
Experiment: Develop a comprehensive report for the following exercises:

Explain the foundational concepts of Generative AI.
Focusing on Generative AI architectures. (like transformers).
Generative AI applications.
Generative AI impact of scaling in LLMs.

## Algorithm:
Step 1: Define Objective

Input: Research problem (Study of Generative AI & LLMs).

Output: Clear goals (Understand foundations, architectures, applications, and scaling effects).

Step 2: Collect Resources

Gather research papers, blogs, and textbooks.

Install required libraries (transformers, torch, datasets).

Identify case studies (ChatGPT, DALL·E, Stable Diffusion).

Step 3: Study Foundational Concepts

Compare discriminative vs generative models.

Review architectures: Autoencoders, GANs, Diffusion, Transformers.

Represent findings in flowcharts/diagrams.

Step 4: Explore Generative AI Architectures (Transformers)

Input: Transformer model (e.g., GPT-2).

Process:

Load pre-trained model.

Run text generation task.

Record outputs.

Output: Example text generations.

Step 5: Applications of Generative AI

Identify domains: text, image, audio, code, healthcare.

Collect 2–3 case studies.

Document observations.

Step 6: Study Scaling Effects in LLMs

Compare small vs large models in terms of:

Parameters, training data size, inference time, quality of output.

Document challenges (energy cost, hallucinations, bias).

Record differences in outputs if tested.

Step 7: Analysis and Observation

Summarize experimental findings:

Quality of generation.

Advantages and limitations.

Impact of scaling.

Step 8: Conclusion & Future Scope

Derive insights on why Generative AI is impactful.

Highlight future improvements (efficiency, ethics, domain specialization).

## Output
[Generative_AI_LLMs_Report.pdf](https://github.com/user-attachments/files/22017202/Generative_AI_LLMs_Report.pdf)


## Result
the result of this experiment is a well-organized, in-depth report that demonstrates conceptual clarity, explains architectures and applications, and critically evaluates how scaling shapes the capabilities and risks of LLMs.
